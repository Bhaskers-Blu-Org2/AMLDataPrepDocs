{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/work-with-data/dataprep/how-to-guides/mount-dataflows.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mounting dataflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will learn how to mount a dataflow that points to a list of files in the cloud to your local compute. *Note: mounting only works on Unix or Unix-like operating systems*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dataflow pointing to some files\n",
    "You will create a dataflow that points to some images in an Azure Blob Container. The dataflow will contain 1 column called `Path` with `StreamInfo` objects inside it, which references the source data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.dataprep as dprep\n",
    "\n",
    "dflow = dprep.Dataflow.get_files('https://dprepdata.blob.core.windows.net/demo/cats/*.jpg')\n",
    "dflow.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you will create a new column that extracts the portable path of all the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.dataprep.api.functions import get_portable_path\n",
    "from azureml.dataprep.api.expressions import col\n",
    "\n",
    "portable_path_col = 'Portable Path'\n",
    "dflow = dflow.add_column(\n",
    "    expression=get_portable_path(col('Path')), \n",
    "    new_column_name=portable_path_col, \n",
    "    prior_column='Path')\n",
    "dflow.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now mount the dataflow and get the size of all the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "    \n",
    "def mount_dataflow():\n",
    "    import uuid\n",
    "    \n",
    "    from azureml.dataprep.fuse.dprepfuse import mount\n",
    "    from os.path import getsize, join\n",
    "    import os\n",
    "    mnts_dir = '/tmp/dprepmounts/'\n",
    "\n",
    "    mount_point = join(mnts_dir, str(uuid.uuid4()))\n",
    "    os.makedirs(mount_point)\n",
    "\n",
    "    with mount(dataflow=dflow, files_column='Path', mount_point=mount_point, foreground=False):\n",
    "        mounted_files = [join(mount_point, path.lstrip('/')) for path in dflow.to_pandas_dataframe()[portable_path_col]]\n",
    "        \n",
    "        for file in mounted_files:\n",
    "            print('{}: {}kB'.format(file, getsize(file) / 1000))\n",
    "            \n",
    "if sys.platform != 'linux':\n",
    "    print('Mounting only works on Unix or Unix-like operating systems.')\n",
    "else:\n",
    "    mount_dataflow()"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "sihhu"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "notice": "Copyright (c) Microsoft Corporation. All rights reserved. Licensed under the MIT License.",
  "test_has_service_dependencies": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
